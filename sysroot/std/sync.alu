//! Thread synchronization primitives

use std::builtins::{Primitive, ZeroSized, Integer};

/// Memory ordering
///
/// Follows C++ memory model ([see here](https://en.cppreference.com/w/c/atomic/memory_order)).
enum Ordering {
    Relaxed = 0,
    // Consume = 1, but it's not included
    Acquire = 2,
    Release = 3,
    AcqRel = 4,
    SeqCst = 5
}

/// Values that can be operated on atomically.
struct Atomic<T: Primitive + !ZeroSized> {
    inner: T
}

impl Atomic<T: Primitive + !ZeroSized> {
    /// Create a new `Atomic` value with the given initial value.
    fn new(inner: T) -> Atomic<T> {
        Atomic { inner: inner }
    }

    /// Loads a value from the atomic variable.
    #[force_inline]
    fn load(self: &Atomic<T>, ordering: Ordering) -> T {
        intrinsics::codegen_func::<T>("__atomic_load_n", &self.inner, ordering as libc::c_int)
    }

    /// Stores a value into the atomic variable.
    #[force_inline]
    fn store(self: &mut Atomic<T>, value: T, ordering: Ordering) {
        intrinsics::codegen_func::<void>("__atomic_store_n", &self.inner, value, ordering as libc::c_int)
    }

    /// Stores a value into the atomic variable, atomically returning the old value.
    #[force_inline]
    fn exchange(self: &mut Atomic<T>, value: T, ordering: Ordering) -> T {
        intrinsics::codegen_func::<T>("__atomic_exchange_n", &self.inner, value, ordering as libc::c_int)
    }

    /// Atomically compares the value in the atomic variable to `expected` and, if they are equal,
    /// sets the atomic variable to `desired`.
    ///
    /// This is the strong version, which will not fail spuriously. See also [compare_exchange_weak].
    #[force_inline]
    fn compare_exchange(
        self: &mut Atomic<T>,
        expected: T,
        desired: T,
        success_ordering: Ordering,
        failure_ordering: Ordering
    ) -> Result<T, T> {
        if intrinsics::codegen_func::<bool>(
            "__atomic_compare_exchange_n",
            &self.inner,
            &expected,
            desired,
            false,
            success_ordering as libc::c_int,
            failure_ordering as libc::c_int
        ) {
            Result::ok(expected)
        } else {
            Result::err(expected)
        }
    }

    /// Atomically compares the value in the atomic variable to `expected` and, if they are equal,
    /// sets the atomic variable to `desired`.
    ///
    /// This is the weak version, which can fail spuriously even when the comparison succeeds.
    #[force_inline]
    fn compare_exchange_weak(
        self: &mut Atomic<T>,
        expected: T,
        desired: T,
        success_ordering: Ordering,
        failure_ordering: Ordering
    ) -> Result<T, T> {
        if intrinsics::codegen_func::<bool>(
            "__atomic_compare_exchange_n",
            &self.inner,
            &expected,
            desired,
            true,
            success_ordering as libc::c_int,
            failure_ordering as libc::c_int
        ) {
            Result::ok(expected)
        } else {
            Result::err(expected)
        }
    }
}

impl Atomic<T: Integer> {
    /// Atomically adds `value` to the atomic variable and returns the old value.
    #[force_inline]
    fn fetch_add(self: &mut Atomic<T>, value: T, ordering: Ordering) -> T {
        intrinsics::codegen_func::<T>("__atomic_fetch_add", &self.inner, value, ordering as libc::c_int)
    }

    /// Atomically subtracts `value` from the atomic variable and returns the old value.
    #[force_inline]
    fn fetch_sub(self: &mut Atomic<T>, value: T, ordering: Ordering) -> T {
        intrinsics::codegen_func::<T>("__atomic_fetch_sub", &self.inner, value, ordering as libc::c_int)
    }

    /// Atomically performs `*self &= value` and returns the old value.
    #[force_inline]
    fn fetch_and(self: &mut Atomic<T>, value: T, ordering: Ordering) -> T {
        intrinsics::codegen_func::<T>("__atomic_fetch_and", &self.inner, value, ordering as libc::c_int)
    }

    /// Atomically performs `*self |= value` and returns the old value.
    #[force_inline]
    fn fetch_or(self: &mut Atomic<T>, value: T, ordering: Ordering) -> T {
        intrinsics::codegen_func::<T>("__atomic_fetch_or", &self.inner, value, ordering as libc::c_int)
    }

    /// Atomically performs `*self ^= value` and returns the old value.
    #[force_inline]
    fn fetch_xor(self: &mut Atomic<T>, value: T, ordering: Ordering) -> T {
        intrinsics::codegen_func::<T>("__atomic_fetch_xor", &self.inner, value, ordering as libc::c_int)
    }

    /// Atomically performs `*self = ~(*self & value)` and returns the old value.
    #[force_inline]
    fn fetch_nand(self: &mut Atomic<T>, value: T, ordering: Ordering) -> T {
        intrinsics::codegen_func::<T>("__atomic_fetch_nand", &self.inner, value, ordering as libc::c_int)
    }
}

/// Memory barrier
#[force_inline]
fn fence(ordering: Ordering) {
    intrinsics::codegen_func::<void>("__atomic_thread_fence", ordering as libc::c_int)
}

/// Compiler-only memory barrier
///
/// This prevents the compiler from reordering memory accesses accrodning to the
/// memory access ordering, but does not prevent hardware reordering.
#[force_inline]
fn compiler_fence(ordering: Ordering) {
    intrinsics::codegen_func::<void>("__atomic_signal_fence", ordering as libc::c_int)
}

/// A mutual exclusion lock (mutex)
///
/// This is a standard pthread mutex.
struct Mutex {
    inner: libc::pthread_mutex_t
}

impl Mutex {
    use std::io::Error;

    /// Creates a new mutex.
    fn new() -> Mutex {
        thread::internal::check_threading!();

        Mutex {
            inner: libc::pthread_mutex_initializer()
        }
    }

    /// Acquires a mutex, blocking the current thread until it can acquire it.
    fn lock(self: &mut Mutex) {
        let ret = libc::pthread_mutex_lock(&self.inner);
        if ret != 0 {
            panic!("pthread_mutex_lock failed: {}", Error::from_errno_custom(ret));
        }
    }

    /// Attempts to acquire a mutex, but does not block.
    ///
    /// Returns `true` if the mutex was successfully acquired, `false` otherwise.
    fn try_lock(self: &mut Mutex) -> bool {
        let ret = libc::pthread_mutex_trylock(&self.inner);
        switch ret {
            0 => true,
            libc::EBUSY => false,
            _ => panic!("pthread_mutex_trylock failed: {}", Error::from_errno_custom(ret))
        }
    }

    /// Releases a mutex.
    fn unlock(self: &mut Mutex) {
        let ret = libc::pthread_mutex_unlock(&self.inner);
        if ret != 0 {
            panic!("pthread_mutex_unlock failed: {}", Error::from_errno_custom(ret));
        }
    }
}

/// Reader-writer lock
///
/// This is a standard pthread rwlock.
struct RwLock {
    inner: libc::pthread_rwlock_t
}

impl RwLock {
    use std::io::Error;

    /// Creates a new reader-writer lock.
    fn new() -> RwLock {
        thread::internal::check_threading!();

        RwLock {
            inner: libc::pthread_rwlock_initializer()
        }
    }

    /// Acquires a reader-writer lock for reading.
    fn read_lock(self: &mut RwLock) {
        let ret = libc::pthread_rwlock_rdlock(&self.inner);
        if ret != 0 {
            panic!("pthread_rwlock_rdlock failed: {}", Error::from_errno_custom(ret));
        }
    }

    /// Attempts to acquire a reader-writer lock for reading.
    ///
    /// Returns `true` if the lock was successfully acquired, `false` otherwise.
    fn try_read_lock(self: &mut RwLock) -> bool {
        let ret = libc::pthread_rwlock_tryrdlock(&self.inner);
        switch ret {
            0 => true,
            libc::EBUSY => false,
            _ => panic!("pthread_rwlock_tryrdlock failed: {}", Error::from_errno_custom(ret))
        }
    }

    /// Acquires a reader-writer lock for writing.
    fn write_lock(self: &mut RwLock) {
        let ret = libc::pthread_rwlock_wrlock(&self.inner);
        if ret != 0 {
            panic!("pthread_rwlock_wrlock failed: {}", Error::from_errno_custom(ret));
        }
    }

    /// Attempts to acquire a reader-writer lock for writing.
    ///
    /// Returns `true` if the lock was successfully acquired, `false` otherwise.
    fn try_write_lock(self: &mut RwLock) -> bool {
        let ret = libc::pthread_rwlock_trywrlock(&self.inner);
        switch ret {
            0 => true,
            libc::EBUSY => false,
            _ => panic!("pthread_rwlock_trywrlock failed: {}", Error::from_errno_custom(ret))
        }
    }

    /// Releases a reader-writer lock.
    fn unlock(self: &mut RwLock) {
        let ret = libc::pthread_rwlock_unlock(&self.inner);
        if ret != 0 {
            panic!("pthread_rwlock_unlock failed: {}", Error::from_errno_custom(ret));
        }
    }
}

/// Condition variable
///
/// This is a standard pthread condition variable.
struct CondVar {
    inner: libc::pthread_cond_t
}

impl CondVar {
    use std::io::Error;

    /// Creates a new condition variable.
    fn new() -> CondVar {
        thread::internal::check_threading!();

        CondVar {
            inner: libc::pthread_cond_initializer()
        }
    }

    /// Waits on a condition variable.
    ///
    /// May return spuriously.
    fn wait(self: &mut CondVar, mutex: &mut Mutex) {
        let ret = libc::pthread_cond_wait(&self.inner, &mutex.inner);
        if ret != 0 {
            panic!("pthread_cond_wait failed: {}", Error::from_errno_custom(ret));
        }
    }

    /// Waits on a condition variable with a timeout.
    ///
    /// Returns `true` if the condition variable was signaled, `false` otherwise. However, since the
    /// condition variable can wake up spuriously, it is not guaranteed that the condition is actually
    /// satisfied.
    fn wait_timeout(self: &mut CondVar, mutex: &mut Mutex, timeout: time::Duration) -> bool {
        let timespec = libc::timespec {
            tv_sec: util::cast(timeout.secs),
            tv_nsec: util::cast(timeout.nanos)
        }
        let ret = libc::pthread_cond_timedwait(&self.inner, &mutex.inner, &timespec);
        switch ret {
            0 => true,
            libc::ETIMEDOUT => false,
            _ => panic!("pthread_cond_timedwait failed: {}", Error::from_errno_custom(ret))
        }
    }

    /// Signals a condition variable, waking up one waiting thread.
    fn notify_one(self: &mut CondVar) {
        let ret = libc::pthread_cond_signal(&self.inner);
        if ret != 0 {
            panic!("pthread_cond_signal failed: {}", Error::from_errno_custom(ret));
        }
    }

    /// Signals a condition variable, waking up all waiting threads.
    fn notify_all(self: &mut CondVar) {
        let ret = libc::pthread_cond_broadcast(&self.inner);
        if ret != 0 {
            panic!("pthread_cond_broadcast failed: {}", Error::from_errno_custom(ret));
        }
    }
}


/// A synchronization primitive that allows multiple threads to wait until the
/// event is signalled.
///
/// Once an event is signalled it can be reset and reused.
///
/// ## Example
/// ```
/// use std::sync::Event;
/// use std::thread::spawn;
///
/// let ev = Event::new();
/// let text: &[u8];
///
/// let t = spawn(|&ev, &text| {
///     text = "Hello, world!";
///     ev.set();
/// });
///
/// ev.wait();
/// assert_eq!(text, "Hello, world!");
///
/// t.join().unwrap();
/// ```
struct Event {
    state: Atomic<usize>
}

impl Event {
    use internal::{EventWaiter, EVENT_SET, EVENT_RESET, EVENT_STATE_MASK};

    /// Create a new event in an unset state
    fn new() -> Event {
        Event {
            state: Atomic::new(EVENT_RESET)
        }
    }

    /// Create a new event in a set state
    fn new_set() -> Event {
        Event {
            state: Atomic::new(EVENT_SET)
        }
    }

    /// Signals the event, waking up all threads that are waiting on it.
    fn set(self: &mut Event) {
        let old_value = self.state.exchange(EVENT_SET, Ordering::AcqRel);
        switch old_value {
            EVENT_SET, EVENT_RESET => {}
            _ => {
                // Wake up some threads
                let waiter = (old_value & ~EVENT_STATE_MASK) as &mut EventWaiter;
                while waiter != null {
                    /// As soon as we set the `signaled` flag, the region of
                    /// memory that waiter points to may be invalidated. So we need
                    /// to store it first.
                    let next = waiter.next;
                    let thread = waiter.thread;
                    waiter.signaled.store(true, Ordering::Release);
                    thread.unpark();
                    waiter = next;
                }
            }
        }
    }

    /// Resets the event, so that it can be waited on and signalled again.
    ///
    /// If event is not in set state, this is a no-op.
    fn reset(self: &mut Event) {
        self.state.compare_exchange(
            EVENT_SET,
            EVENT_RESET,
            Ordering::Release,
            Ordering::Relaxed
        );
    }

    /// Checks if the event is signalled.
    fn is_set(self: &Event) -> bool {
        self.state.load(Ordering::Acquire) == EVENT_SET
    }

    /// Waits for the event to be signalled.
    fn wait(self: &mut Event) {
        let state = self.state.load(Ordering::Acquire);
        loop {
            if state == EVENT_SET {
                return;
            }

            // This is a clever idea I stole from Rust's Once, a linked-list of nodes
            // on the stack. Since the threads are sleeping, the address will
            // remain valid.
            let waiter = EventWaiter {
                thread: thread::Thread::current(),
                signaled: Atomic::new(false),
                next: (state & ~EVENT_STATE_MASK) as &mut EventWaiter
            }

            let maybe_replaced = self.state.compare_exchange(
                state,
                &waiter as usize,
                Ordering::Release,
                Ordering::Relaxed
            );

            if !maybe_replaced.is_ok {
                // Someone beat us to the punch
                state = maybe_replaced.unwrap_err();
                continue;
            }

            while !waiter.signaled.load(Ordering::Acquire) {
                thread::Thread::park();
            }
            return;
        }
    }
}

/// A one-shot channel (future).
///
/// `Oneshot` can be used to send a single value between threads. Multiple threads can wait on it and
/// they will all receive the same value.
///
/// ## Example
/// ```
/// use std::sync::Oneshot;
/// use std::thread::spawn;
///
/// let one_shot: Oneshot<i32> = Oneshot::new();
/// let t = spawn(|&one_shot| {
///     one_shot.send(42);
/// });
///
/// let value = one_shot.recv();
/// assert_eq!(value, 42);
///
/// t.join().unwrap();
/// ```
struct Oneshot<T> {
    _event: Event,
    _value: T
}

impl Oneshot<T> {
    /// Creates a new one-shot channel.
    fn new() -> Oneshot<T> {
        Oneshot::<T> {
            _event: Event::new(),
            _value: mem::uninitialized()
        }
    }

    /// Creates a completed one-shot channel from a value
    fn from_value(value: T) -> Oneshot<T> {
        Oneshot::<T> {
            _event: Event::new_set(),
            _value: value
        }
    }

    /// Sets the value of the channel.
    ///
    /// If the channel is already closed, this will return `Result::err(ChannelError::Closed)`.
    ///
    /// It is undefined behavior to call this function more than once on a single channel.
    fn send(self: &mut Oneshot<T>, value: T) {
        debug_assert!(!self._event.is_set());

        self._value = value;
        self._event.set();
    }

    /// Gets the value of the channel.
    ///
    /// If the channel's value has already been set, this will return immediately. Otherwise,
    /// it will block until the value is set.
    fn recv(self: &mut Oneshot<T>) -> T {
        self._event.wait();
        self._value
    }

    /// Tries to get the value of the channel
    ///
    /// If the channel's value has not been set, this will return [channel::ChannelError::WouldBlock].
    fn try_recv(self: &mut Oneshot<T>) -> Result<T, channel::ChannelError> {
        if self._event.is_set() {
            Result::ok(self._value)
        } else {
            Result::err(channel::ChannelError::WouldBlock)
        }
    }
}

mod internal {
    const EVENT_RESET: usize = 0x0;
    const EVENT_SET: usize = 0x1;
    const EVENT_STATE_MASK: usize = 0x1;

    #[align(4)]
    struct EventWaiter {
        thread: thread::Thread,
        signaled: Atomic<bool>,
        next: &mut EventWaiter,
    }
}

#[cfg(all(test, test_std))]
mod tests {
    use time::Duration;

    #[test]
    fn test_ordering_values_match() {
        // This test asserts that the ordering constant values we hardcode above match the
        // builtin constants in the C compiler.

        macro match($a, $b) {
            assert_eq!($a as libc::c_int, intrinsics::codegen_const::<libc::c_int>($b));
        }

        match!(Ordering::Relaxed, "__ATOMIC_RELAXED");
        match!(Ordering::Acquire, "__ATOMIC_ACQUIRE");
        match!(Ordering::Release, "__ATOMIC_RELEASE");
        match!(Ordering::AcqRel, "__ATOMIC_ACQ_REL");
        match!(Ordering::SeqCst, "__ATOMIC_SEQ_CST");
    }

    #[test]
    fn test_load() {
        let a: Atomic<i32> = Atomic::new(42);
        assert_eq!(a.load(Ordering::Relaxed), 42);
    }

    #[test]
    fn test_store() {
        let a: Atomic<i32> = Atomic::new(42);
        a.store(43, Ordering::Relaxed);
        assert_eq!(a.load(Ordering::Relaxed), 43);
    }

    #[test]
    fn test_exchange() {
        let a: Atomic<i32> = Atomic::new(42);
        assert_eq!(a.exchange(43, Ordering::Relaxed), 42);
        assert_eq!(a.load(Ordering::Relaxed), 43);
    }

    #[test]
    fn test_compare_exchange() {
        let a: Atomic<i32> = Atomic::new(42);
        assert_eq!(a.compare_exchange(42, 43, Ordering::Relaxed, Ordering::Relaxed), Result::ok(42));
        assert_eq!(a.load(Ordering::Relaxed), 43);
        assert_eq!(a.compare_exchange(44, 45, Ordering::Relaxed, Ordering::Relaxed), Result::err(43));
        assert_eq!(a.load(Ordering::Relaxed), 43);
    }

    #[test]
    fn test_compare_exchange_weak() {
        let a: Atomic<i32> = Atomic::new(42);
        assert_eq!(a.compare_exchange_weak(42, 43, Ordering::Relaxed, Ordering::Relaxed), Result::ok(42));
        assert_eq!(a.load(Ordering::Relaxed), 43);
        assert_eq!(a.compare_exchange_weak(44, 45, Ordering::Relaxed, Ordering::Relaxed), Result::err(43));
        assert_eq!(a.load(Ordering::Relaxed), 43);
    }

    #[test]
    fn test_fetch_add() {
        let a: Atomic<u32> = Atomic::new(42u32);
        assert_eq!(a.fetch_add(1, Ordering::Relaxed), 42u32);
        assert_eq!(a.load(Ordering::Relaxed), 43u32);
    }

    #[test]
    fn test_fetch_sub() {
        let a: Atomic<u32> = Atomic::new(42u32);
        assert_eq!(a.fetch_sub(1, Ordering::Relaxed), 42u32);
        assert_eq!(a.load(Ordering::Relaxed), 41u32);
    }

    #[test]
    fn test_fetch_and() {
        let a: Atomic<u32> = Atomic::new(42u32);
        assert_eq!(a.fetch_and(0xFu32, Ordering::Relaxed), 42u32);
        assert_eq!(a.load(Ordering::Relaxed), 10u32);
    }

    #[test]
    fn test_fetch_or() {
        let a: Atomic<u32> = Atomic::new(42u32);
        assert_eq!(a.fetch_or(0xFu32, Ordering::Relaxed), 42u32);
        assert_eq!(a.load(Ordering::Relaxed), 47u32);
    }

    #[test]
    fn test_fetch_xor() {
        let a: Atomic<u32> = Atomic::new(42u32);
        assert_eq!(a.fetch_xor(0xFu32, Ordering::Relaxed), 42u32);
        assert_eq!(a.load(Ordering::Relaxed), 37u32);
    }

    #[test]
    fn test_fetch_nand() {
        let a: Atomic<u32> = Atomic::new(42u32);
        assert_eq!(a.fetch_nand(0xFu32, Ordering::Relaxed), 42u32);
        assert_eq!(a.load(Ordering::Relaxed), 0xfffffff5u32);
    }

    #[cfg(threading)]
    #[test]
    fn test_mutex() {
        let a = Mutex::new();
        a.lock();
        thread::spawn(|&a| {
            assert_eq!(a.try_lock(), false);
        }).join().unwrap();
        a.unlock();
        assert_eq!(a.try_lock(), true);
        a.unlock();
    }

    #[cfg(threading)]
    #[test]
    fn test_rwlock() {
        let a = RwLock::new();
        a.read_lock();
        thread::spawn(|&a| {
            assert_eq!(a.try_write_lock(), false);
            assert_eq!(a.try_read_lock(), true);
            a.unlock();
        }).join().unwrap();
        a.unlock();

        a.write_lock();
        thread::spawn(|&a| {
            assert_eq!(a.try_read_lock(), false);
            assert_eq!(a.try_write_lock(), false);
        }).join().unwrap();
        a.unlock();
    }

    #[cfg(threading)]
    #[test]
    fn test_condvar() {
        use thread::{spawn, Thread};

        let counter = 0;

        let flag = Atomic::new(false);
        let mutex = Mutex::new();
        let condvar = CondVar::new();

        let t = spawn(|&counter, &condvar, &mutex, &flag| {
            /// Ensure the main thread gets the mutex first;
            while !flag.load(Ordering::SeqCst) {
                Thread::park();
            }

            mutex.lock();
            defer mutex.unlock();

            counter += 1;
            condvar.notify_one();
        });

        mutex.lock();
        defer mutex.unlock();

        assert!(!condvar.wait_timeout(&mutex, time::Duration::zero()));

        flag.store(true, Ordering::SeqCst);
        t.thread().unpark();

        while counter == 0 {
            condvar.wait(&mutex);
        }

        assert_eq!(mutex.try_lock(), false);

        t.join().unwrap();
        assert_eq!(counter, 1);
    }

    #[cfg(threading)]
    #[test]
    fn test_event() {
        let ev = Event::new();
        assert_eq!(ev.is_set(), false);
        ev.set();
        assert_eq!(ev.is_set(), true);
        ev.wait();
        ev.reset();
        assert_eq!(ev.is_set(), false);
    }

    #[cfg(threading)]
    #[test]
    fn test_event_blocking() {
        use thread::{spawn, Thread};
        let ev1 = Event::new();
        let ev2 = Event::new();

        let t1 = spawn(|&ev1, &ev2| {
            ev1.wait();
            ev1.reset();
            ev2.set();
        });

        ev1.set();
        ev2.wait();

        assert_eq!(ev1.is_set(), false);
        assert_eq!(ev2.is_set(), true);

        t1.join().unwrap();
    }

    #[cfg(threading)]
    #[test]
    fn test_oneshot() {
        let chan: Oneshot<i32> = Oneshot::new();
        assert_eq!(chan.try_recv(), Result::err(channel::ChannelError::WouldBlock));
        chan.send(1337);
        assert_eq!(chan.try_recv(), Result::ok(1337));
        assert_eq!(chan.recv(), 1337);
    }

    #[cfg(threading)]
    #[test]
    fn test_oneshot_completed() {
        let chan: Oneshot<i32> = Oneshot::from_value(1337);
        assert_eq!(chan.recv(), 1337);
    }

    #[cfg(threading)]
    #[test]
    fn test_oneshot_blocking() {
        use thread::{spawn, Thread};

        let chan: Oneshot<i32> = Oneshot::new();
        let main_thread = Thread::current();
        let flag = Atomic::new(2);

        let t1 = spawn(|&chan, &flag, =main_thread| -> i32 {
            if flag.fetch_sub(1, Ordering::SeqCst) == 1 {
                main_thread.unpark();
            }
            chan.recv() + 1
        });

        let t2 = spawn(|&chan, &flag, =main_thread| -> i32 {
            if flag.fetch_sub(1, Ordering::SeqCst) == 1 {
                main_thread.unpark();
            }
            chan.recv() + 2
        });

        while flag.load(Ordering::SeqCst) != 0 {
            Thread::park();
        }
        /// Make sure the threads are really blocked.
        for i in 0..100 {
            Thread::yield();
        }

        chan.send(42);
        assert_eq!(t1.join().unwrap(), 43);
        assert_eq!(t2.join().unwrap(), 44);
    }
}
