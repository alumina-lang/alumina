//! Thread synchronization primitives

use std::builtins::{Primitive, ZeroSized, Integer};

/// Memory ordering
///
/// Follows C++ memory model ([see here](https://en.cppreference.com/w/c/atomic/memory_order)).
enum Ordering {
    Relaxed = 0,
    // Consume = 1, but it's not included
    Acquire = 2,
    Release = 3,
    AcqRel = 4,
    SeqCst = 5
}

/// Values that can be operated on atomically.
struct Atomic<T: Primitive + !ZeroSized> {
    inner: T
}

impl Atomic<T: Primitive + !ZeroSized> {
    /// Create a new `Atomic` value with the given initial value.
    fn new(inner: T) -> Atomic<T> {
        Atomic { inner: inner }
    }

    /// Loads a value from the atomic variable.
    #[force_inline]
    fn load(self: &Atomic<T>, ordering: Ordering) -> T {
        intrinsics::codegen_func::<T>("__atomic_load_n", &self.inner, ordering as libc::c_int)
    }

    /// Stores a value into the atomic variable.
    #[force_inline]
    fn store(self: &mut Atomic<T>, value: T, ordering: Ordering) {
        intrinsics::codegen_func::<void>("__atomic_store_n", &self.inner, value, ordering as libc::c_int)
    }

    /// Stores a value into the atomic variable, atomically returning the old value.
    #[force_inline]
    fn exchange(self: &mut Atomic<T>, value: T, ordering: Ordering) -> T {
        intrinsics::codegen_func::<T>("__atomic_exchange_n", &self.inner, value, ordering as libc::c_int)
    }

    /// Atomically compares the value in the atomic variable to `expected` and, if they are equal,
    /// sets the atomic variable to `desired`.
    ///
    /// This is the strong version, which will not fail spuriously. See also [compare_exchange_weak].
    #[force_inline]
    fn compare_exchange(
        self: &mut Atomic<T>,
        expected: T,
        desired: T,
        success_ordering: Ordering,
        failure_ordering: Ordering
    ) -> Result<T, T> {
        if intrinsics::codegen_func::<bool>(
            "__atomic_compare_exchange_n",
            &self.inner,
            &expected,
            desired,
            false,
            success_ordering as libc::c_int,
            failure_ordering as libc::c_int
        ) {
            Result::ok(expected)
        } else {
            Result::err(expected)
        }
    }

    /// Atomically compares the value in the atomic variable to `expected` and, if they are equal,
    /// sets the atomic variable to `desired`.
    ///
    /// This is the weak version, which can fail spuriously even when the comparison succeeds.
    #[force_inline]
    fn compare_exchange_weak(
        self: &mut Atomic<T>,
        expected: T,
        desired: T,
        success_ordering: Ordering,
        failure_ordering: Ordering
    ) -> Result<T, T> {
        if intrinsics::codegen_func::<bool>(
            "__atomic_compare_exchange_n",
            &self.inner,
            &expected,
            desired,
            true,
            success_ordering as libc::c_int,
            failure_ordering as libc::c_int
        ) {
            Result::ok(expected)
        } else {
            Result::err(expected)
        }
    }
}

impl Atomic<T: Integer> {
    /// Atomically adds `value` to the atomic variable and returns the old value.
    #[force_inline]
    fn fetch_add(self: &mut Atomic<T>, value: T, ordering: Ordering) -> T {
        intrinsics::codegen_func::<T>("__atomic_fetch_add", &self.inner, value, ordering as libc::c_int)
    }

    /// Atomically subtracts `value` from the atomic variable and returns the old value.
    #[force_inline]
    fn fetch_sub(self: &mut Atomic<T>, value: T, ordering: Ordering) -> T {
        intrinsics::codegen_func::<T>("__atomic_fetch_sub", &self.inner, value, ordering as libc::c_int)
    }

    /// Atomically performs `*self &= value` and returns the old value.
    #[force_inline]
    fn fetch_and(self: &mut Atomic<T>, value: T, ordering: Ordering) -> T {
        intrinsics::codegen_func::<T>("__atomic_fetch_and", &self.inner, value, ordering as libc::c_int)
    }

    /// Atomically performs `*self |= value` and returns the old value.
    #[force_inline]
    fn fetch_or(self: &mut Atomic<T>, value: T, ordering: Ordering) -> T {
        intrinsics::codegen_func::<T>("__atomic_fetch_or", &self.inner, value, ordering as libc::c_int)
    }

    /// Atomically performs `*self ^= value` and returns the old value.
    #[force_inline]
    fn fetch_xor(self: &mut Atomic<T>, value: T, ordering: Ordering) -> T {
        intrinsics::codegen_func::<T>("__atomic_fetch_xor", &self.inner, value, ordering as libc::c_int)
    }

    /// Atomically performs `*self = ~(*self & value)` and returns the old value.
    #[force_inline]
    fn fetch_nand(self: &mut Atomic<T>, value: T, ordering: Ordering) -> T {
        intrinsics::codegen_func::<T>("__atomic_fetch_nand", &self.inner, value, ordering as libc::c_int)
    }
}

/// Memory barrier
#[force_inline]
fn fence(ordering: Ordering) {
    intrinsics::codegen_func::<void>("__atomic_thread_fence", ordering as libc::c_int)
}

/// Compiler-only memory barrier
///
/// This prevents the compiler from reordering memory accesses accrodning to the
/// memory access ordering, but does not prevent hardware reordering.
#[force_inline]
fn compiler_fence(ordering: Ordering) {
    intrinsics::codegen_func::<void>("__atomic_signal_fence", ordering as libc::c_int)
}

/// A mutual exclusion lock (mutex)
///
/// This is a standard pthread mutex.
struct Mutex {
    inner: libc::pthread_mutex_t
}

impl Mutex {
    use std::io::Error;

    /// Creates a new mutex.
    fn new() -> Mutex {
        Mutex {
            inner: libc::pthread_mutex_initializer()
        }
    }

    /// Acquires a mutex, blocking the current thread until it can acquire it.
    fn lock(self: &mut Mutex) {
        let ret = libc::pthread_mutex_lock(&self.inner);
        if ret != 0 {
            panic!("pthread_mutex_lock failed: {}", Error::from_errno_custom(ret));
        }
    }

    /// Attempts to acquire a mutex, but does not block.
    ///
    /// Returns `true` if the mutex was successfully acquired, `false` otherwise.
    fn try_lock(self: &mut Mutex) -> bool {
        let ret = libc::pthread_mutex_trylock(&self.inner);
        switch ret {
            0 => true,
            libc::EBUSY => false,
            _ => panic!("pthread_mutex_trylock failed: {}", Error::from_errno_custom(ret))
        }
    }

    /// Releases a mutex.
    fn unlock(self: &mut Mutex) {
        let ret = libc::pthread_mutex_unlock(&self.inner);
        if ret != 0 {
            panic!("pthread_mutex_unlock failed: {}", Error::from_errno_custom(ret));
        }
    }
}

/// Reader-writer lock
///
/// This is a standard pthread rwlock.
struct RwLock {
    inner: libc::pthread_rwlock_t
}

impl RwLock {
    use std::io::Error;

    /// Creates a new reader-writer lock.
    fn new() -> RwLock {
        RwLock {
            inner: libc::pthread_rwlock_initializer()
        }
    }

    /// Acquires a reader-writer lock for reading.
    fn read_lock(self: &mut RwLock) {
        let ret = libc::pthread_rwlock_rdlock(&self.inner);
        if ret != 0 {
            panic!("pthread_rwlock_rdlock failed: {}", Error::from_errno_custom(ret));
        }
    }

    /// Attempts to acquire a reader-writer lock for reading.
    ///
    /// Returns `true` if the lock was successfully acquired, `false` otherwise.
    fn try_read_lock(self: &mut RwLock) -> bool {
        let ret = libc::pthread_rwlock_tryrdlock(&self.inner);
        switch ret {
            0 => true,
            libc::EBUSY => false,
            _ => panic!("pthread_rwlock_tryrdlock failed: {}", Error::from_errno_custom(ret))
        }
    }

    /// Acquires a reader-writer lock for writing.
    fn write_lock(self: &mut RwLock) {
        let ret = libc::pthread_rwlock_wrlock(&self.inner);
        if ret != 0 {
            panic!("pthread_rwlock_wrlock failed: {}", Error::from_errno_custom(ret));
        }
    }

    /// Attempts to acquire a reader-writer lock for writing.
    ///
    /// Returns `true` if the lock was successfully acquired, `false` otherwise.
    fn try_write_lock(self: &mut RwLock) -> bool {
        let ret = libc::pthread_rwlock_trywrlock(&self.inner);
        switch ret {
            0 => true,
            libc::EBUSY => false,
            _ => panic!("pthread_rwlock_trywrlock failed: {}", Error::from_errno_custom(ret))
        }
    }

    /// Releases a reader-writer lock.
    fn unlock(self: &mut RwLock) {
        let ret = libc::pthread_rwlock_unlock(&self.inner);
        if ret != 0 {
            panic!("pthread_rwlock_unlock failed: {}", Error::from_errno_custom(ret));
        }
    }
}

/// Condition variable
///
/// This is a standard pthread condition variable.
struct CondVar {
    inner: libc::pthread_cond_t
}

impl CondVar {
    use std::io::Error;

    /// Creates a new condition variable.
    fn new() -> CondVar {
        CondVar {
            inner: libc::pthread_cond_initializer()
        }
    }

    /// Waits on a condition variable.
    ///
    /// May return spuriously.
    fn wait(self: &mut CondVar, mutex: &mut Mutex) {
        let ret = libc::pthread_cond_wait(&self.inner, &mutex.inner);
        if ret != 0 {
            panic!("pthread_cond_wait failed: {}", Error::from_errno_custom(ret));
        }
    }

    /// Waits on a condition variable with a timeout.
    ///
    /// Returns `true` if the condition variable was signaled, `false` otherwise. However, since the
    /// condition variable can wake up spuriously, it is not guaranteed that the condition is actually
    /// satisfied.
    fn wait_timeout(self: &mut CondVar, mutex: &mut Mutex, timeout: time::Duration) -> bool {
        let timespec = libc::timespec {
            tv_sec: util::cast(timeout.secs),
            tv_nsec: util::cast(timeout.nanos)
        }
        let ret = libc::pthread_cond_timedwait(&self.inner, &mutex.inner, &timespec);
        switch ret {
            0 => true,
            libc::ETIMEDOUT => false,
            _ => panic!("pthread_cond_timedwait failed: {}", Error::from_errno_custom(ret))
        }
    }

    /// Signals a condition variable, waking up one waiting thread.
    fn notify_one(self: &mut CondVar) {
        let ret = libc::pthread_cond_signal(&self.inner);
        if ret != 0 {
            panic!("pthread_cond_signal failed: {}", Error::from_errno_custom(ret));
        }
    }

    /// Signals a condition variable, waking up all waiting threads.
    fn notify_all(self: &mut CondVar) {
        let ret = libc::pthread_cond_broadcast(&self.inner);
        if ret != 0 {
            panic!("pthread_cond_broadcast failed: {}", Error::from_errno_custom(ret));
        }
    }
}

/// Iterator over values of [Channel].
struct ChannelIterator<T> {
    inner: &mut Channel<T>
}

impl ChannelIterator<T> {
    /// @ iter::Iterator::next
    fn next(self: &mut ChannelIterator<T>) -> Option<T> {
        let ret = self.inner.recv();
        if ret.is_ok {
            Option::some(ret.inner.ok)
        } else {
            assert_eq!(ret.inner.err, ChannelError::Closed);
            Option::none()
        }
    }

    mixin iter::Iterator<ChannelIterator<T>, T>;
    mixin iter::IteratorExt<ChannelIterator<T>, T>;
}

/// Error returned by [Channel] operations.
enum ChannelError {
    Closed,
    WouldBlock
}

impl ChannelError {
    use fmt::{write, Formattable, Formatter, Result};
    use cmp::Equatable;

    /// @ Equatable::equals
    fn equals(self: &ChannelError, other: &ChannelError) -> bool {
        *self as i32 == *other as i32
    }

    /// @ Formattable::fmt
    fn fmt<F: Formatter<F>>(self: &ChannelError, f: &mut F) -> Result {
        switch *self {
            ChannelError::Closed => write!(f, "channel closed"),
            ChannelError::WouldBlock => write!(f, "channel would block")
            _ => unreachable!()
        }
    }

    mixin cmp::Equatable<ChannelError>;
}

/// A simple bounded synchronous queue.
///
/// Uses a ring buffer and [Mutex] and [CondVar] to provide mutual exclusion and signalling.
///
/// # Example
/// ```
/// use std::sync::Channel;
/// use std::thread::spawn;
///
/// // Space for 10 elements
/// let chan: Channel<i32> = Channel::new(5);
///
/// let t = spawn(|&chan| {
///     for i in 0..10 {
///         chan.send(i).unwrap();
///     }
///     chan.close();
/// });
///
/// /// Prints all the values.
/// for i in chan {
///     println!("{}", i);
/// }
///
/// t.join().unwrap();
/// ```
struct Channel<T> {
    mutex: Mutex,
    cond: CondVar,
    buffer: &mut [T],
    closed: bool,
    reader: usize,
    writer: usize
}

impl Channel<T> {
    use time::{Instant, Duration};
    use builtins::Callable;

    /// Creates a new channel with a given capacity
    fn new(capacity: usize) -> Channel<T> {
        assert!(capacity >= 1);

        Channel {
            mutex: Mutex::new(),
            cond: CondVar::new(),
            buffer: mem::slice::alloc::<T>(capacity + 1),
            closed: false,
            reader: 0,
            writer: 0,
        }
    }

    /// Send a value to the channel.
    ///
    /// This function will block if the channel is full.
    fn send(self: &mut Channel<T>, value: T) -> Result<(), ChannelError> {
        self._wait(Channel::_send_cond::<T>);
        self._do_send(value)
    }

    /// Try to send a value to the channel.
    ///
    /// If the channel is full, this function will return `Result::err(ChannelError::WouldBlock)`.
    fn try_send(self: &mut Channel<T>, value: T) -> Result<(), ChannelError> {
        self._try_wait(Channel::_send_cond::<T>)?;
        self._do_send(value)
    }

    /// Try to send a value to the channel with a timeout.
    ///
    /// If the channel is full, this function will return `Result::err(ChannelError::WouldBlock)`.
    fn send_timeout(self: &mut Channel<T>, value: T, timeout: Duration) -> Result<(), ChannelError> {
        self._wait_timeout(Channel::_send_cond::<T>, timeout)?;
        self._do_send(value)
    }

    /// Receive a value from the channel.
    ///
    /// This function will block if the channel is empty.
    fn recv(self: &mut Channel<T>) -> Result<T, ChannelError> {
        self._wait(Channel::_recv_cond::<T>);
        self._do_recv()
    }

    /// Try to receive a value from the channel.
    ///
    /// If the channel is empty, this function will return `Result::err(ChannelError::WouldBlock)`.
    fn try_recv(self: &mut Channel<T>) -> Result<T, ChannelError>  {
        self._try_wait(Channel::_recv_cond::<T>)?;
        self._do_recv()
    }

    /// Try to receive a value from the channel with a timeout.
    ///
    /// If the channel is empty, this function will return `Result::err(ChannelError::WouldBlock)`.
    fn recv_timeout(self: &mut Channel<T>, timeout: Duration) -> Result<T, ChannelError> {
        self._wait_timeout(Channel::_recv_cond::<T>, timeout)?;
        self._do_recv()
    }

    /// Close the channel.
    ///
    /// All subsequent calls to `send` or `recv` (or their variants) will return `Result::err(ChannelError::Closed)`.
    fn close(self: &mut Channel<T>) {
        self.mutex.lock();
        let cond = self.reader == self.writer;
        self.closed = true;
        self.mutex.unlock();

        if cond {
            self.cond.notify_all();
        } else {
            self.cond.notify_one();
        }
    }

    fn _wait<F: Callable<(&Channel<T>), bool>>(self: &mut Channel<T>, cond: F) {
        self.mutex.lock();
        while !cond(self) {
            self.cond.wait(&self.mutex);
        }
    }

    fn _try_wait<F: Callable<(&Channel<T>), bool>>(self: &mut Channel<T>, cond: F) -> Result<(), ChannelError> {
        self.mutex.lock();
        if !cond(self) {
            self.mutex.unlock();
            return Result::err(ChannelError::WouldBlock);
        }

        Result::ok(())
    }

    fn _wait_timeout<F: Callable<(&Channel<T>), bool>>(self: &mut Channel<T>, cond: F, timeout: Duration) -> Result<(), ChannelError> {
        let start = Instant::now();
        self.mutex.lock();

        while !cond(self) {
            let remaining = timeout.sub(
                &Instant::now().duration_since(&start)
            );

            if remaining.is_negative() {
                self.mutex.unlock();
                return Result::err(ChannelError::WouldBlock);
            }
            self.cond.wait_timeout(&self.mutex, remaining);
        }

        Result::ok(())
    }

    fn _recv_cond(self: &Channel<T>) -> bool {
        self.reader != self.writer || self.closed
    }

    fn _send_cond(self: &Channel<T>) -> bool {
        (self.reader != (self.writer + 1) % self.buffer.len) || self.closed
    }

    fn _do_recv(self: &mut Channel<T>) -> Result<T, ChannelError> {
        // Don't check self.closed, there may still be items to read
        if self.reader == self.writer {
            self.mutex.unlock();
            return Result::err(ChannelError::Closed);
        }

        let value = self.buffer[self.reader];
        self.reader = (self.reader + 1) % self.buffer.len;
        self.mutex.unlock();
        self.cond.notify_one();
        Result::ok(value)
    }

    fn _do_send(self: &mut Channel<T>, value: T) -> Result<(), ChannelError> {
        if self.closed {
            self.mutex.unlock();
            return Result::err(ChannelError::Closed);
        }

        self.buffer[self.writer] = value;
        self.writer = (self.writer + 1) % self.buffer.len;

        self.mutex.unlock();
        self.cond.notify_one();
        Result::ok(())
    }

    /// @ iter::Iterable::iter
    fn iter(self: &mut Channel<T>) -> ChannelIterator<T> {
        ChannelIterator {
            inner: self
        }
    }

    /// @ mem::Freeable::free
    fn free(self: &mut Channel<T>) {
        self.buffer.free();
    }
}

/// A synchronization primitive that allows multiple threads to wait until the
/// event is signalled.
///
/// Once an event is signalled it can be reset and reused.
///
/// # Example
/// ```
/// use std::sync::Event;
/// use std::thread::spawn;
///
/// let ev = Event::new();
/// let text: &[u8];
///
/// let t = spawn(|&ev, &text| {
///     text = "Hello, world!";
///     ev.set();
/// });
///
/// ev.wait();
/// assert_eq!(text, "Hello, world!");
///
/// t.join().unwrap();
/// ```
struct Event {
    state: Atomic<usize>
}

impl Event {
    use internal::{EventWaiter, COMPLETE, INCOMPLETE, STATE_MASK};

    /// Create a new event
    fn new() -> Event {
        Event {
            state: Atomic::new(INCOMPLETE)
        }
    }

    /// Signals the event, waking up all threads that are waiting on it.
    fn set(self: &mut Event) {
        let old_value = self.state.exchange(COMPLETE, Ordering::AcqRel);
        switch old_value {
            INCOMPLETE, COMPLETE => {}
            _ => {
                // Wake up some threads
                let waiter = (old_value & ~STATE_MASK) as &mut EventWaiter;
                while waiter != null {
                    waiter.signaled.store(true, Ordering::Release);
                    waiter.thread.unpark();
                    waiter = waiter.next;
                }
            }
        }
    }

    /// Resets the event, so that it can be waited on and signalled again.
    ///
    /// If event is not in set state, this is a no-op.
    fn reset(self: &mut Event) {
        self.state.compare_exchange(
            COMPLETE,
            INCOMPLETE,
            Ordering::Release,
            Ordering::Relaxed
        );
    }

    /// Checks if the event is signalled.
    fn is_set(self: &Event) -> bool {
        self.state.load(Ordering::Acquire) == COMPLETE
    }

    /// Waits for the event to be signalled.
    fn wait(self: &mut Event) {
        let state = self.state.load(Ordering::Acquire);
        loop {
            if state == COMPLETE {
                return;
            }

            // This is a super clever idea I stole from Rust's Once, a linked-list
            // of nodes on the stack. Since the threads are sleeping, the address will
            // remain valid.
            let waiter = EventWaiter {
                thread: thread::Thread::current(),
                signaled: Atomic::new(false),
                next: (state & ~STATE_MASK) as &mut EventWaiter
            }

            let maybe_replaced = self.state.compare_exchange(
                state,
                &waiter as usize,
                Ordering::Release,
                Ordering::Relaxed
            );

            if !maybe_replaced.is_ok {
                // Someone beat us to the punch
                state = maybe_replaced.unwrap_err();
                continue;
            }

            while !waiter.signaled.load(Ordering::Acquire) {
                thread::Thread::park();
            }
            return;
        }
    }
}

/// A one-shot channel (future).
///
/// A one-shot channel is a channel that can only be sent to once. Multiple threads can wait on it and
/// they will all receive the same value.
///
/// # Example
/// ```
/// use std::sync::Oneshot;
/// use std::thread::spawn;
///
/// let one_shot: Oneshot<i32> = Oneshot::new();
/// let t = spawn(|&one_shot| {
///     one_shot.send(42);
/// });
///
/// let value = one_shot.recv();
/// assert_eq!(value, 42);
///
/// t.join().unwrap();
/// ```
struct Oneshot<T> {
    _event: Event,
    _value: T
}

impl Oneshot<T> {
    /// Creates a new one-shot channel.
    fn new() -> Oneshot<T> {
        Oneshot::<T> {
            _event: Event::new(),
            _value: mem::uninitialized()
        }
    }

    /// Sets the value of the channel.
    ///
    /// If the channel is already closed, this will return `Result::err(ChannelError::Closed)`.
    ///
    /// It is undefined behavior to call this function more than once on a single channel.
    fn send(self: &mut Oneshot<T>, value: T) {
        debug_assert!(!self._event.is_set());

        self._value = value;
        self._event.set();
    }

    /// Gets the value of the channel.
    ///
    /// If the channel's value has already been set, this will return immediately. Otherwise,
    /// it will block until the value is set.
    fn recv(self: &mut Oneshot<T>) -> T {
        self._event.wait();
        self._value
    }

    /// Tries to get the value of the channel
    ///
    /// If the channel's value has not been set, this will return [ChannelError::WouldBlock].
    fn try_recv(self: &mut Oneshot<T>) -> Result<T, ChannelError> {
        if self._event.is_set() {
            Result::ok(self._value)
        } else {
            Result::err(ChannelError::WouldBlock)
        }
    }
}

mod internal {
    const INCOMPLETE: usize = 0x0;
    const COMPLETE: usize = 0x1;
    const STATE_MASK: usize = 0x1;

    #[align(4)]
    struct EventWaiter {
        thread: thread::Thread,
        signaled: Atomic<bool>,
        next: &mut EventWaiter,
    }
}

#[cfg(all(test, test_std))]
mod tests {
    use time::Duration;

    #[test]
    fn test_ordering_values_match() {
        // This test asserts that the ordering constant values we hardcode above match the
        // builtin constants in the C compiler.

        macro match($a, $b) {
            assert_eq!($a as libc::c_int, intrinsics::codegen_const::<libc::c_int>($b));
        }

        match!(Ordering::Relaxed, "__ATOMIC_RELAXED");
        match!(Ordering::Acquire, "__ATOMIC_ACQUIRE");
        match!(Ordering::Release, "__ATOMIC_RELEASE");
        match!(Ordering::AcqRel, "__ATOMIC_ACQ_REL");
        match!(Ordering::SeqCst, "__ATOMIC_SEQ_CST");
    }

    #[test]
    fn test_load() {
        let a: Atomic<i32> = Atomic::new(42);
        assert_eq!(a.load(Ordering::Relaxed), 42);
    }

    #[test]
    fn test_store() {
        let a: Atomic<i32> = Atomic::new(42);
        a.store(43, Ordering::Relaxed);
        assert_eq!(a.load(Ordering::Relaxed), 43);
    }

    #[test]
    fn test_exchange() {
        let a: Atomic<i32> = Atomic::new(42);
        assert_eq!(a.exchange(43, Ordering::Relaxed), 42);
        assert_eq!(a.load(Ordering::Relaxed), 43);
    }

    #[test]
    fn test_compare_exchange() {
        let a: Atomic<i32> = Atomic::new(42);
        assert_eq!(a.compare_exchange(42, 43, Ordering::Relaxed, Ordering::Relaxed), Result::ok(42));
        assert_eq!(a.load(Ordering::Relaxed), 43);
        assert_eq!(a.compare_exchange(44, 45, Ordering::Relaxed, Ordering::Relaxed), Result::err(43));
        assert_eq!(a.load(Ordering::Relaxed), 43);
    }

    #[test]
    fn test_compare_exchange_weak() {
        let a: Atomic<i32> = Atomic::new(42);
        assert_eq!(a.compare_exchange_weak(42, 43, Ordering::Relaxed, Ordering::Relaxed), Result::ok(42));
        assert_eq!(a.load(Ordering::Relaxed), 43);
        assert_eq!(a.compare_exchange_weak(44, 45, Ordering::Relaxed, Ordering::Relaxed), Result::err(43));
        assert_eq!(a.load(Ordering::Relaxed), 43);
    }

    #[test]
    fn test_fetch_add() {
        let a: Atomic<u32> = Atomic::new(42u32);
        assert_eq!(a.fetch_add(1, Ordering::Relaxed), 42u32);
        assert_eq!(a.load(Ordering::Relaxed), 43u32);
    }

    #[test]
    fn test_fetch_sub() {
        let a: Atomic<u32> = Atomic::new(42u32);
        assert_eq!(a.fetch_sub(1, Ordering::Relaxed), 42u32);
        assert_eq!(a.load(Ordering::Relaxed), 41u32);
    }

    #[test]
    fn test_fetch_and() {
        let a: Atomic<u32> = Atomic::new(42u32);
        assert_eq!(a.fetch_and(0xFu32, Ordering::Relaxed), 42u32);
        assert_eq!(a.load(Ordering::Relaxed), 10u32);
    }

    #[test]
    fn test_fetch_or() {
        let a: Atomic<u32> = Atomic::new(42u32);
        assert_eq!(a.fetch_or(0xFu32, Ordering::Relaxed), 42u32);
        assert_eq!(a.load(Ordering::Relaxed), 47u32);
    }

    #[test]
    fn test_fetch_xor() {
        let a: Atomic<u32> = Atomic::new(42u32);
        assert_eq!(a.fetch_xor(0xFu32, Ordering::Relaxed), 42u32);
        assert_eq!(a.load(Ordering::Relaxed), 37u32);
    }

    #[test]
    fn test_fetch_nand() {
        let a: Atomic<u32> = Atomic::new(42u32);
        assert_eq!(a.fetch_nand(0xFu32, Ordering::Relaxed), 42u32);
        assert_eq!(a.load(Ordering::Relaxed), 0xfffffff5u32);
    }

    #[cfg(threading)]
    #[test]
    fn test_mutex() {
        let a = Mutex::new();
        a.lock();
        thread::spawn(|&a| {
            assert_eq!(a.try_lock(), false);
        }).join().unwrap();
        a.unlock();
        assert_eq!(a.try_lock(), true);
        a.unlock();
    }

    #[cfg(threading)]
    #[test]
    fn test_rwlock() {
        let a = RwLock::new();
        a.read_lock();
        thread::spawn(|&a| {
            assert_eq!(a.try_write_lock(), false);
            assert_eq!(a.try_read_lock(), true);
            a.unlock();
        }).join().unwrap();
        a.unlock();

        a.write_lock();
        thread::spawn(|&a| {
            assert_eq!(a.try_read_lock(), false);
            assert_eq!(a.try_write_lock(), false);
        }).join().unwrap();
        a.unlock();
    }

    #[cfg(threading)]
    #[test]
    fn test_condvar() {
        use thread::{spawn, Thread};

        let counter = 0;

        let flag = Atomic::new(false);
        let mutex = Mutex::new();
        let condvar = CondVar::new();

        let t = spawn(|&counter, &condvar, &mutex, &flag| {
            /// Ensure the main thread gets the mutex first;
            while !flag.load(Ordering::SeqCst) {
                Thread::park();
            }

            mutex.lock();
            defer mutex.unlock();

            counter += 1;
            condvar.notify_one();
        });

        mutex.lock();
        defer mutex.unlock();

        assert!(!condvar.wait_timeout(&mutex, time::Duration::zero()));

        flag.store(true, Ordering::SeqCst);
        t.thread().unpark();

        while counter == 0 {
            condvar.wait(&mutex);
        }

        assert_eq!(mutex.try_lock(), false);

        t.join().unwrap();
        assert_eq!(counter, 1);
    }

    #[cfg(threading)]
    #[test]
    fn test_channel() {
        let chan: Channel<i32> = Channel::new(3);
        assert_eq!(chan.send(42), Result::ok(()));
        assert_eq!(chan.recv(), Result::ok(42));
    }

    #[cfg(threading)]
    #[test]
    fn test_channel_closed() {
        let chan: Channel<i32> = Channel::new(3);
        assert_eq!(chan.send(42), Result::ok(()));
        assert_eq!(chan.send(42), Result::ok(()));
        chan.close();

        assert_eq!(chan.send(42), Result::err(ChannelError::Closed));
        assert_eq!(chan.recv(), Result::ok(42));
        assert_eq!(chan.recv(), Result::ok(42));
        assert_eq!(chan.recv(), Result::err(ChannelError::Closed));
    }

    #[cfg(threading)]
    #[test]
    fn test_channel_try() {
        let chan: Channel<i32> = Channel::new(3);
        assert_eq!(chan.try_send(42), Result::ok(()));
        assert_eq!(chan.try_send(42), Result::ok(()));
        assert_eq!(chan.try_send(42), Result::ok(()));
        assert_eq!(chan.try_send(42), Result::err(ChannelError::WouldBlock));
        assert_eq!(chan.try_recv(), Result::ok(42));
        assert_eq!(chan.try_recv(), Result::ok(42));
        assert_eq!(chan.try_recv(), Result::ok(42));
        assert_eq!(chan.try_recv(), Result::err(ChannelError::WouldBlock));
    }

    #[cfg(threading)]
    #[test]
    fn test_channel_timeout() {
        let chan: Channel<i32> = Channel::new(3);
        assert_eq!(chan.send_timeout(42, Duration::zero()), Result::ok(()));
        assert_eq!(chan.send_timeout(42, Duration::zero()), Result::ok(()));
        assert_eq!(chan.send_timeout(42, Duration::zero()), Result::ok(()));
        assert_eq!(chan.send_timeout(42, Duration::zero()), Result::err(ChannelError::WouldBlock));
        assert_eq!(chan.recv_timeout(Duration::zero()), Result::ok(42));
        assert_eq!(chan.recv_timeout(Duration::zero()), Result::ok(42));
        assert_eq!(chan.recv_timeout(Duration::zero()), Result::ok(42));
        assert_eq!(chan.recv_timeout(Duration::zero()), Result::err(ChannelError::WouldBlock));
    }

    #[cfg(threading)]
    #[test]
    fn test_event() {
        let ev = Event::new();
        assert_eq!(ev.is_set(), false);
        ev.set();
        assert_eq!(ev.is_set(), true);
        ev.wait();
        ev.reset();
        assert_eq!(ev.is_set(), false);
    }

    #[cfg(threading)]
    #[test]
    fn test_event_blocking() {
        use thread::{spawn, Thread};
        let ev1 = Event::new();
        let ev2 = Event::new();

        let t1 = spawn(|&ev1, &ev2| {
            ev1.wait();
            ev1.reset();
            ev2.set();
        });

        ev1.set();
        ev2.wait();

        assert_eq!(ev1.is_set(), false);
        assert_eq!(ev2.is_set(), true);

        t1.join().unwrap();
    }

    #[cfg(threading)]
    #[test]
    fn test_oneshot() {
        let chan: Oneshot<i32> = Oneshot::new();
        assert_eq!(chan.try_recv(), Result::err(ChannelError::WouldBlock));
        chan.send(1337);
        assert_eq!(chan.try_recv(), Result::ok(1337));
        assert_eq!(chan.recv(), 1337);
    }

    #[cfg(threading)]
    #[test]
    fn test_oneshot_blocking() {
        use thread::{spawn, Thread};

        let chan: Oneshot<i32> = Oneshot::new();
        let main_thread = Thread::current();
        let flag = Atomic::new(2);

        let t1 = spawn(|&chan, &flag, =main_thread| -> i32 {
            if flag.fetch_sub(1, Ordering::SeqCst) == 1 {
                main_thread.unpark();
            }
            chan.recv() + 1
        });

        let t2 = spawn(|&chan, &flag, =main_thread| -> i32 {
            if flag.fetch_sub(1, Ordering::SeqCst) == 1 {
                main_thread.unpark();
            }
            chan.recv() + 2
        });

        while flag.load(Ordering::SeqCst) != 0 {
            Thread::park();
        }
        /// Make sure the threads are really blocked.
        for i in 0..100 {
            Thread::yield();
        }

        chan.send(42);
        assert_eq!(t1.join().unwrap(), 43);
        assert_eq!(t2.join().unwrap(), 44);
    }
}
