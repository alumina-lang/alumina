#[cfg(any(target_os="linux", target_os="macos", target_os="android"))]
{
    use unix::{
        print, println, eprint, eprintln,
        Error, FileDescriptor, Pipe, StdioStream,
        stdin, stdout, stderr, anonymous_pipe
    }
}

protocol AsFileDescriptor<Self> {
    fn as_fd(self: &Self) -> FileDescriptor;
}

protocol Readable<Self> {
    use collections::Vector;
    use internal::default_read_exact;

    fn read(self: &mut Self, buf: &mut [u8]) -> Result<usize, Error>;
    fn read_exact(self: &mut Self, buf: &mut [u8]) -> Result<(), Error> {
        self.default_read_exact(buf)
    }

    fn read_to_end(self: &mut Self, buf: &mut Vector<u8>) -> Result<usize, Error> {;
        let start_len = buf.len();
        let start_cap = buf.capacity();

        loop {
            if buf.capacity() == buf.len() {
                buf.reserve(32);
            }
            let read = self.read(buf.spare_capacity())?;
            if read == 0 {
                return Result::ok(buf.len() - start_len);
            } else {
                buf._length = buf.len() + read;
            }

            // Optimization for the case where the initial vector had exactly 
            // enough capacity - avoid doubling the vector if the next read will
            // return EOF by using a small stack buffer instead.
            if buf.capacity() == buf.len() && buf.capacity() == start_cap {
                let probe: [u8; 32];
                let read = self.read(probe.as_slice_mut())?;
                if read == 0 {
                    return Result::ok(buf.len() - start_len);
                } else {
                    buf.extend_from_slice(probe.as_slice()[..read])
                }
            }
        }
    }
}

protocol Writable<Self> {
    fn write(self: &mut Self, buf: &[u8]) -> Result<usize, Error>;
    fn write_all(self: &mut Self, buf: &[u8]) -> Result<(), Error> {

        while buf.len > 0 {
            let written_bytes = self.write(buf)?;
            if written_bytes == 0 {
                return Result::err(Error::eof());
            }
            buf = buf[written_bytes..];
        }

        Result::ok(())
    }
    fn flush(self: &mut Self) -> Result<(), Error>;
}

enum SeekFrom {
    Beginning,
    Current,
    End
}

protocol Seekable<Self> {
    fn seek(self: &mut Self, whence: SeekFrom, offset: i64) -> Result<i64, Error>;
    fn rewind(self: &mut Self) -> Result<(), Error> {
        self.seek(SeekFrom::Beginning, 0)?;
        
        Result::ok(())
    }

    fn position(self: &mut Self) -> Result<u64, Error> {
        self.seek(SeekFrom::Current, 0)
    }
}

struct StringWriter {
    string: &mut collections::Vector<u8>,
}

impl StringWriter {
    fn new(string: &mut collections::Vector<u8>) -> StringWriter {
        StringWriter {
            string: string
        }
    }

    fn write(self: &mut StringWriter, buf: &[u8]) -> Result<usize, Error> {
        self.string.extend_from_slice(buf);
        Result::ok(buf.len)
    }

    fn flush(self: &mut StringWriter) -> Result<(), Error> {
        Result::ok(())
    }

    mixin Writable<StringWriter>;
}

protocol BufferedReadable<Self: Readable<Self>> {
    fn fill_buffer(self: &mut Self) -> Result<&[u8], Error>;
    fn consume(self: &mut Self, amount: usize)
}

struct BufferedReader<R: Readable<R>> {
    inner: &mut R,
    buf: &mut [u8],
    pos: usize,
    cap: usize,
}

impl BufferedReader<R: Readable<R>> {
    use std::mem::copy_nonoverlapping;
    use internal::default_read_exact;

    /// Create a BufferedReader with a heap-allocated buffer of the given size.
    fn new(inner: &mut R, buf_size: usize) -> BufferedReader<R> {
        from_slice(inner, mem::alloc::<u8>(buf_size))
    }

    /// Creates a BufferedReader from an existing-buffer, potentially
    /// avoiding a heap allocation.
    fn from_slice(inner: &mut R, buf: &mut [u8]) -> BufferedReader<R> {
        BufferedReader {
            inner: inner,
            buf: buf,
            pos: 0,
            cap: 0,
        }
    }

    fn fill_buffer(self: &mut BufferedReader<R>) -> Result<&[u8], Error> {
        if self.pos == self.cap {
            self.cap = self.inner.read(self.buf)?;
            self.pos = 0;
        }

        Result::ok(self.buf[self.pos..self.cap] as &[u8])
    }

    fn consume(self: &mut BufferedReader<R>, amount: usize) {
        self.pos = math::min(self.pos + amount, self.cap);
    }

    fn read(self: &mut BufferedReader<R>, buf: &mut [u8]) -> Result<usize, Error> {
        let slice = self.fill_buffer()?;

        let nread = math::min(buf.len, slice.len);
        if nread > 0 {
            slice[..nread].copy_nonoverlapping(&buf[0]);
            self.consume(nread);
        }

        Result::ok(nread)
    }

    fn read_exact(self: &mut BufferedReader<R>, buf: &mut [u8]) -> Result<(), Error> {
        if self.cap - self.pos >= buf.len {
            if buf.len > 0 {
                self.buf[self.pos..self.pos + buf.len].copy_nonoverlapping(&buf[0]);
                self.consume(buf.len);
            }
            return Result::ok(());
        }

        self.default_read_exact(buf)
    }

    fn free(self: &mut BufferedReader<R>) {
        use std::mem::free;
        self.buf.free();
    }

    fn move(self: &mut BufferedReader<R>) -> BufferedReader<R> {
        let ret = *self;
        self.buf = mem::slice::empty();
        ret
    }

    mixin Readable<BufferedReader<R>>;
}

impl BufferedReader<R: Seekable<R>> {
    fn seek(self: &mut BufferedReader<R>, whence: SeekFrom, offset: i64) -> Result<i64, Error> {
        let res = if whence == SeekFrom::Current {
            let remainder = (self.cap - self.pos) as i64;
            let res = self.inner.seek(SeekFrom::Current, offset - remainder)?;
            res
        } else {
            self.inner.seek(whence, offset)?
        };

        self.cap = 0;
        self.pos = 0;

        Result::ok(res)
    }

    fn position(self: &mut BufferedReader<R>) -> Result<u64, ()> {
        self.seek(SeekFrom::Current, 0)
    }

    mixin Seekable<BufferedReader<R>>;
}

struct BufferedWriter<W: Writable<W>> {
    buf: &mut [u8],
    pos: usize,
    inner: &mut W
}

impl BufferedWriter<W: Writable<W>> {
    use mem::copy_nonoverlapping;

    /// Create a BufferedWriter with a heap-allocated buffer of the given size.
    fn new(inner: &mut W, buf_size: usize) -> BufferedWriter<W> {
        from_slice(inner, mem::alloc::<u8>(buf_size))
    }

    /// Creates a BufferedWriter from an existing-buffer, potentially
    /// avoiding a heap allocation.
    fn from_slice(inner: &mut W, buf: &mut [u8]) -> BufferedWriter<W> {
        BufferedWriter {
            inner: inner,
            buf: buf,
            pos: 0
        }
    }

    #[cold]
    #[inline(never)]
    fn write_full(self: &mut BufferedWriter<W>, buf: &[u8]) -> result::Result<usize, Error> {
        if buf.len > self.buf.len - self.pos {
            self.flush_buffer()?;
        }
     
        if buf.len >= self.buf.len  {
            // Bypass the buffer if we need to write more than buffer size
            self.inner.write(buf)
        } else {
            self._write_to_buffer(buf);
            Result::ok(buf.len)
        }
    }

    #[cold]
    #[inline(never)]
    fn write_all_full(self: &mut BufferedWriter<W>, buf: &[u8]) -> result::Result<(), Error> {
        if buf.len > self.buf.len - self.pos {
            self.flush_buffer()?;
        }

        if buf.len >= self.buf.len {
            // Bypass the buffer if we need to write more than buffer size
            self.inner.write_all(buf)
        } else {
            self._write_to_buffer(buf);
            Result::ok(())
        }
    }

    #[inline]
    fn write(self: &mut BufferedWriter<W>, buf: &[u8]) -> result::Result<usize, Error> {
        if buf.len < self.buf.len - self.pos {
            self._write_to_buffer(buf);
            Result::ok(buf.len)
        } else {
            self.write_full(buf)
        }
    }

    #[inline]
    fn write_all(self: &mut BufferedWriter<W>, buf: &[u8]) -> result::Result<(), Error> {
        if buf.len < self.buf.len - self.pos {
            self._write_to_buffer(buf);
            Result::ok(())
        } else {
            self.write_all_full(buf)
        }
    }

    fn flush_buffer(self: &mut BufferedWriter<W>) -> result::Result<(), Error> {
        // This will return an EOF error, if we are not able to write everything.
        // since we have accepted bytes that  are not written to the underlying 
        // writer and not signalled an EOF.
        self.inner.write_all(self.buf[..self.pos])?;
        self.pos = 0;

        Result::ok(())
    }

    fn flush(self: &mut BufferedWriter<W>) -> result::Result<(), Error> {
        self.flush_buffer()?;
        self.inner.flush()
    }

    #[inline]
    fn _write_to_buffer(self: &mut BufferedWriter<W>, buf: &[u8]) {
        if buf.len > 0 {
            // This guard is technically redundant, but to avoid the debug assertion
            // when indexing past the end of the buffer with 0-length writes.
            buf.copy_nonoverlapping(&self.buf[self.pos]);
            self.pos += buf.len;
        }
    }

    fn free(self: &mut BufferedWriter<W>) {
        use std::mem::free;
        free(self.buf);
    }

    fn move(self: &mut BufferedWriter<W>) -> BufferedWriter<W> {
        let ret = *self;
        self.buf = mem::slice::empty();
        ret
    }
}

// BufferedWriter implements Formatter, so it can be used as a sink in write!(...)
impl BufferedWriter<W: Writable<W>> {
    #[inline]
    fn write_str(self: &mut BufferedWriter<W>, buf: &[u8]) -> Result<(), fmt::Error> {
        self.write_all(buf).map_err(fmt::Error::from::<Error>)
    }

    mixin fmt::Formatter<BufferedWriter<W>>;
}


const DEFAULT_BUFFER_SIZE: usize = 8192;

// Extension methods
fn copy<S: Readable<S>, D: Writable<D>>(src: &mut S, dst: &mut D) -> result::Result<u64, Error> {
    let buf = mem::alloc::<u8>(DEFAULT_BUFFER_SIZE);
    defer mem::free(buf);
    
    copy_using(src, dst, buf)
}

fn copy_using<S: Readable<S>, D: Writable<D>>(src: &mut S, dst: &mut D, buffer: &mut [u8]) -> result::Result<u64, Error> {
    let read = 0u64;
    loop {
        let n = src.read(buffer)?;
        read += n as u64;
        if n == 0 {
            break;
        }
        dst.write_all(buffer[0..n])?;
    }

    Result::ok(read)
}    

fn read_byte<R: Readable<R>>(reader: &mut R) -> result::Result<u8, Error> {
    let buf: [u8; 1];
    reader.read_exact(&buf)?;

    Result::ok(buf[0])
}

fn read_until<R: BufferedReadable<R>>(r: &mut R, delim: u8, buf: &mut collections::Vector<u8>) -> result::Result<usize, Error> {
    use string::find_char;

    let read = 0usize;
    loop {
        let available = r.fill_buffer()?;
        let ret = available.find_char(delim);

        let (done, used) = if ret.is_some {
            buf.extend_from_slice(available[..ret.inner + 1]);
            (true, ret.inner + 1)
        } else {
            buf.extend_from_slice(available);
            (false, available.len)
        };

        r.consume(used);
        read += used;
        if done || used == 0 {
            return Result::ok(read);
        }
    }
}

struct LineIterator<R: BufferedReadable<R>> {
    line_buf: collections::Vector<u8>,
    reader: &mut R,
}

/// An iterator over the lines of a buffered reader. The iterator maintains an internal
/// heap-allocated buffer of the line's contents, which is reused between lines.
impl LineIterator<R: BufferedReadable<R>> {
    use std::iter::Iterator;

    fn with_line_buffer(reader: &mut R, line_buf: collections::Vector<u8>) -> LineIterator<R> {
        LineIterator {
            reader: reader,
            line_buf: line_buf
        }
    }

    fn with_capacity(reader: &mut R, capacity: usize) -> LineIterator<R> {
        with_line_buffer(reader, collections::Vector::with_capacity(capacity))
    }

    fn new(reader: &mut R) -> LineIterator<R> {
        with_capacity(reader, 0)
    }

    fn next(self: &mut LineIterator<R>) -> Option<Result<&[u8], Error>> {
        self.line_buf.clear();

        let res = self.reader.read_until('\n', &self.line_buf);
        if !res.is_ok {
            return Option::some(Result::err(res.unwrap_err()));
        }

        if res.unwrap() == 0 {
            return Option::none();
        }

        if self.line_buf.last() == Option::some('\n') {
            self.line_buf.pop();
            if self.line_buf.last() == Option::some('\r') {
                self.line_buf.pop();
            }
        }

        Option::some(Result::ok(self.line_buf.as_slice()))
    }

    fn iter(self: &mut LineIterator<R>) -> &mut LineIterator<R> {
        self
    }

    fn free(self: &mut LineIterator<R>) {
        self.line_buf.free();
    }

    fn move(self: &mut LineIterator<R>) -> LineIterator<R> {
        LineIterator::<R> {
            reader: self.reader,
            line_buf: self.line_buf.move()
        }
    }

    mixin iter::IteratorExt<LineIterator<R>, Result<&[u8], Error>>;
    mixin<Other: iter::Iterator<Other, Result<&[u8], Error>>> 
        iter::IteratorExtOther<LineIterator<R>, Other, Result<&[u8], Error>>;
}

fn lines<R: BufferedReadable<R>>(reader: &mut R) -> LineIterator<R> {
    LineIterator::new(reader)
}


mod internal {
    fn default_read_exact<T: Readable<T>>(self: &mut T, buf: &mut [u8]) -> Result<(), Error> {
        while buf.len > 0 {
            let read_bytes = self.read(buf)?;
            if read_bytes == 0 {
                return Result::err(Error::eof());
            }
            buf = buf[read_bytes..];
        }

        Result::ok(())
    }
}


#[cfg(all(test, test_std))]
mod tests {

}
